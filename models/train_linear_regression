{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decd030b",
   "metadata": {
    "_cell_guid": "d028a48b-4f7f-45fe-8362-ea86d716e0a2",
    "_uuid": "94e04a98-d6e4-4f81-8c77-4dc2a1aac68c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-06T10:50:42.285362Z",
     "iopub.status.busy": "2024-06-06T10:50:42.284908Z",
     "iopub.status.idle": "2024-06-06T10:50:45.071473Z",
     "shell.execute_reply": "2024-06-06T10:50:45.070128Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.79447,
     "end_time": "2024-06-06T10:50:45.073872",
     "exception": false,
     "start_time": "2024-06-06T10:50:42.279402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this notebook training time is  2024-06-06 10:50:45\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import dill\n",
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "print(\"this notebook training time is \", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a0dd57",
   "metadata": {
    "_cell_guid": "ab7fc3eb-4570-4cb3-b29b-88a885c4d2a3",
    "_uuid": "8bf5b763-b33c-4229-8785-0bab1b71d6f0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-06T10:50:45.083109Z",
     "iopub.status.busy": "2024-06-06T10:50:45.082570Z",
     "iopub.status.idle": "2024-06-06T10:50:45.111659Z",
     "shell.execute_reply": "2024-06-06T10:50:45.110550Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.036575,
     "end_time": "2024-06-06T10:50:45.114282",
     "exception": false,
     "start_time": "2024-06-06T10:50:45.077707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    seed=2024\n",
    "    num_folds=10\n",
    "    TARGET_NAME ='target'\n",
    "    batch_size=1000\n",
    "    \n",
    "import random\n",
    "\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "seed_everything(Config.seed)\n",
    "\n",
    "colname2dtype=pd.read_csv(\"/kaggle/input/home-credit-inconsistent-data-types/colname2dtype.csv\")\n",
    "colname=colname2dtype['Column'].values\n",
    "dtype=colname2dtype['DataType'].values\n",
    "\n",
    "dtype2pl={}\n",
    "dtype2pl['Int64']=pl.Int64\n",
    "dtype2pl['Float64']=pl.Float64\n",
    "dtype2pl['String']=pl.String\n",
    "dtype2pl['Boolean']=pl.String\n",
    "\n",
    "colname2dtype={}\n",
    "for idx in range(len(colname)):\n",
    "    colname2dtype[colname[idx]]=dtype2pl[dtype[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b650cb86",
   "metadata": {
    "_cell_guid": "0c4c4bac-a2cf-4082-a394-4879516fecd7",
    "_uuid": "30d1460a-a4d2-4d2e-b663-42e874de84a9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-06T10:50:45.124082Z",
     "iopub.status.busy": "2024-06-06T10:50:45.123674Z",
     "iopub.status.idle": "2024-06-06T10:53:02.056728Z",
     "shell.execute_reply": "2024-06-06T10:53:02.055576Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 136.941714,
     "end_time": "2024-06-06T10:53:02.059726",
     "exception": false,
     "start_time": "2024-06-06T10:50:45.118012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train base file after break.number 1\n",
      "------------------------------\n",
      "train applprev_2 file after break. number:1\n",
      "------------------------------\n",
      "credit bureau b num 2\n",
      "train debitcard file after break num 1\n",
      "train deposit file num 1\n",
      "train other file after break number 1\n",
      "person 1 num 1\n",
      "train person2 file after break number 1\n",
      "static_0 file num 2(3)\n",
      "train static_cb_file after break num 1\n",
      "------------------------------\n",
      "train tax_a file after break num 1\n",
      "------------------------------\n",
      "train tax_b file after break num 1\n",
      "------------------------------\n",
      "train tax_c file after break num 1\n",
      "------------------------------\n",
      "test base file after break.number 1\n",
      "------------------------------\n",
      "test applprev_2 file after break. number:1\n",
      "------------------------------\n",
      "credit bureau b num 2\n",
      "test debitcard file after break num 1\n",
      "test deposit file num 1\n",
      "test other file after break number 1\n",
      "person 1 num 1\n",
      "test person2 file after break number 1\n",
      "static_0 file num 2(3)\n",
      "test static_cb_file after break num 1\n",
      "------------------------------\n",
      "test tax_a file after break num 1\n",
      "------------------------------\n",
      "test tax_b file after break num 1\n",
      "------------------------------\n",
      "test tax_c file after break num 1\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def find_df_null_col(df,margin=0.975):\n",
    "    cols=[]\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().mean()>margin:\n",
    "            cols.append(col)\n",
    "    return cols\n",
    "\n",
    "def find_last_case_id(df,id='case_id'):\n",
    "    df_copy=df.clone()\n",
    "    df_tail=df.tail(1)\n",
    "    \n",
    "    df_copy=df_copy.with_columns(pl.col(id).shift(-1).alias(f\"{id}_shift_-1\"))\n",
    "    df_last=df_copy.filter(pl.col(id)-pl.col(f'{id}_shift_-1')!=0).drop(f'{id}_shift_-1')\n",
    "    \n",
    "    df_last=pl.concat([df_last,df_tail])\n",
    "    \n",
    "    del df_copy,df_tail\n",
    "    gc.collect()\n",
    "    return df_last\n",
    "\n",
    "def df_fillna(df,col,method=None):\n",
    "    if method ==None:\n",
    "        pass\n",
    "    if method == \"forward\":\n",
    "        df = df.select([pl.col(col).fill_null('forward')])\n",
    "    else:\n",
    "        df=df.with_columns(pl.col(col).fill_null(method).alias(col))\n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df,col,unique):\n",
    "    \n",
    "    if len(unique)==2:\n",
    "        df=df.with_columns((pl.col(col)==unique[0]).cast(pl.Int8).alias(f\"{col}_{unique[0]}\"))\n",
    "    else:\n",
    "        for idx in range(len(unique)):\n",
    "            df=df.with_columns((pl.col(col)==unique[idx]).cast(pl.Int8).alias(f\"{col}_{unique[idx]}\"))\n",
    "    return df.drop(col)\n",
    "\n",
    "def last_features_merge(feats,last_df,last_features=[]):\n",
    "    \n",
    "    last_df=last_df.select(['case_id']+[last[0] for last in last_features])\n",
    "    \n",
    "    for last in last_features:\n",
    "        col,fill=last\n",
    "        last_df=df_fillna(last_df,col,method=fill)\n",
    "    \n",
    "    feats=feats.join(last_df,on='case_id',how='left')\n",
    "    return feats\n",
    "\n",
    "def group_features_merge(feats,group_df,group_features=[],group_name='applprev2'):\n",
    "    \n",
    "    group_df=group_df.select(['case_id']+[g[0] for g in group_features])\n",
    "    \n",
    "    for group in group_features:\n",
    "        if group_df[group[0]].dtype==pl.String:\n",
    "            col,fill,one_hot=group\n",
    "            group_df=df_fillna(group_df,col,method=fill)\n",
    "            if one_hot==None:\n",
    "                group_df=group_df.drop(col) \n",
    "            else:\n",
    "                group_df=one_hot_encoder(group_df,col,one_hot)\n",
    "                for value in one_hot:\n",
    "                    new_col=f\"{col}_{value}\"\n",
    "                    feat=feat=group_df.group_by('case_id').agg( \n",
    "                                               pl.mean(new_col).alias(f\"mean_{group_name}_{new_col}\"),\n",
    "                                               pl.std(new_col).alias(f\"std_{group_name}_{new_col}\"),\n",
    "                                               pl.count(new_col).alias(f\"count_{group_name}_{new_col}\"),\n",
    "                                             )\n",
    "                    feats=feats.join(feat,on='case_id',how='left')\n",
    "        else:\n",
    "            col,fill=group\n",
    "            group_df=df_fillna(group_df,col,method=fill)\n",
    "            feat=group_df.group_by('case_id').agg( pl.max(col).alias(f\"max_{group_name}_{col}\"),\n",
    "                                   pl.mean(col).alias(f\"mean_{group_name}_{col}\"),\n",
    "                                   pl.median(col).alias(f\"median_{group_name}_{col}\"),\n",
    "                                   pl.std(col).alias(f\"std_{group_name}_{col}\"),\n",
    "                                   pl.min(col).alias(f\"min_{group_name}_{col}\"),\n",
    "                                   pl.count(col).alias(f\"count_{group_name}_{col}\"),\n",
    "                                   pl.sum(col).alias(f\"sum_{group_name}_{col}\"),\n",
    "                                   pl.n_unique(col).alias(f\"n_unique_{group_name}_{col}\"),\n",
    "                                   pl.first(col).alias(f\"first_{group_name}_{col}\"),\n",
    "                                   pl.last(col).alias(f\"last_{group_name}_{col}\")\n",
    "                                 )\n",
    "            feats=feats.join(feat,on='case_id',how='left')\n",
    "    return feats\n",
    "\n",
    "def set_table_dtypes(df):\n",
    "    for col in df.columns:\n",
    "        df=df.with_columns(pl.col(col).cast(colname2dtype[col]).alias(col))\n",
    "    return df\n",
    "\n",
    "def preprocessor(mode='train'):\n",
    "    print(f\"{mode} base file after break.number 1\")\n",
    "    feats=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_base.csv\").pipe(set_table_dtypes)\n",
    "    feats=feats.drop(['date_decision','MONTH','WEEK_NUM'])\n",
    "    print(\"-\"*30)\n",
    "    \n",
    "    print(f\"{mode} applprev_2 file after break. number:1\")\n",
    "    applprev2=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_applprev_2.csv\").pipe(set_table_dtypes)\n",
    "    applprev2=applprev2.with_columns(\n",
    "                \n",
    "               ( (pl.col('cacccardblochreas_147M')!=pl.col('cacccardblochreas_147M'))&(pl.col('conts_type_509L')!=pl.col('conts_type_509L')) )\\\n",
    "                .alias(\"no_credit\")\n",
    "                )\n",
    "    applprev2=applprev2.with_columns(\n",
    "                \n",
    "                ( (pl.col('cacccardblochreas_147M')!=pl.col('cacccardblochreas_147M'))&(pl.col('conts_type_509L')==pl.col('conts_type_509L'))) \\\n",
    "                .alias(\"no_frozen_credit\").cast(pl.Int8)\n",
    "                )\n",
    "    applprev2=applprev2.with_columns(\n",
    "                \n",
    "                (pl.col('cacccardblochreas_147M')==pl.col('cacccardblochreas_147M'))\\\n",
    "                .alias(\"frozen_credit\").cast(pl.Int8)\n",
    "                )\n",
    "    \n",
    "    applprev2_last=find_last_case_id(applprev2)\n",
    "    \n",
    "    last_features=[['conts_type_509L','WHATSAPP'],\n",
    "                   ['no_credit',0],\n",
    "                   ['no_frozen_credit',0],\n",
    "                   ['frozen_credit',0]\n",
    "                  ]\n",
    "    feats=last_features_merge(feats,applprev2_last,last_features)\n",
    "    \n",
    "    group_features=[['cacccardblochreas_147M','a55475b1',\\\n",
    "                     [\"P19_60_110\",\"P17_56_144\",\"a55475b1\",\"P201_63_60\",\"P127_74_114\",\"P133_119_56\",\"P41_107_150\",\"P23_105_103\"\"P33_145_161\"]],\n",
    "                    ['credacc_cards_status_52L','UNCONFIRMED',\\\n",
    "                     ['BLOCKED','UNCONFIRMED','RENEWED', 'CANCELLED', 'INACTIVE', 'ACTIVE']],\n",
    "                     ['num_group1',0],\n",
    "                   ['num_group2',0],\n",
    "                   ]\n",
    "    feats=group_features_merge(feats,applprev2,group_features,group_name='applprev2')\n",
    "    del applprev2,applprev2_last\n",
    "    gc.collect()\n",
    "    print(\"-\"*30)\n",
    "    \n",
    "    print(\"credit bureau b num 2\")\n",
    "    bureau_b_1=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_credit_bureau_b_1.csv\").pipe(set_table_dtypes)\n",
    "    bureau_b_2=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_credit_bureau_b_2.csv\").pipe(set_table_dtypes)\n",
    "    bureau_b_1_last=find_last_case_id(bureau_b_1,id='case_id')\n",
    "    bureau_b_2_last=find_last_case_id(bureau_b_2,id='case_id')\n",
    "    feats=feats.join(bureau_b_1_last,on='case_id',how='left')\n",
    "    feats=feats.join(bureau_b_2_last,on='case_id',how='left')\n",
    "\n",
    "    del bureau_b_1,bureau_b_1_last,bureau_b_2,bureau_b_2_last\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"{mode} debitcard file after break num 1\")\n",
    "    debitcard=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_debitcard_1.csv\").pipe(set_table_dtypes)\n",
    "    debitcard_last=find_last_case_id(debitcard,id='case_id')\n",
    "    \n",
    "    last_features=[['last180dayaveragebalance_704A',0],\n",
    "                   ['last180dayturnover_1134A',30000],\n",
    "                   ['last30dayturnover_651A',0]\n",
    "                  ]\n",
    "    feats=last_features_merge(feats,debitcard_last,last_features)\n",
    "    group_features=[['num_group1',0]\n",
    "                  ]\n",
    "    feats=group_features_merge(feats,debitcard,group_features,group_name='debitcard')\n",
    "    del debitcard,debitcard_last\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"{mode} deposit file num 1\")\n",
    "    deposit=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_deposit_1.csv\").pipe(set_table_dtypes)\n",
    "    \n",
    "    for idx in range(1,len(deposit.columns)):\n",
    "        col=deposit.columns[idx]\n",
    "        column_type = deposit[col].dtype\n",
    "        is_numeric = (column_type == pl.datatypes.Int64) or (column_type == pl.datatypes.Float64) \n",
    "        if is_numeric:\n",
    "            feat=deposit.group_by('case_id').agg( pl.max(col).alias(f\"max_deposit_{col}\"),\n",
    "                                           pl.mean(col).alias(f\"mean_deposit_{col}\"),\n",
    "                                           pl.median(col).alias(f\"median_deposit_{col}\"),\n",
    "                                           pl.std(col).alias(f\"std_deposit_{col}\"),\n",
    "                                           pl.min(col).alias(f\"min_deposit_{col}\"),\n",
    "                                           pl.count(col).alias(f\"count_deposit_{col}\"),\n",
    "                                           pl.sum(col).alias(f\"sum_deposit_{col}\"),\n",
    "                                           pl.n_unique(col).alias(f\"n_unique_deposit_{col}\"),\n",
    "                                           pl.first(col).alias(f\"first_deposit_{col}\"),\n",
    "                                           pl.last(col).alias(f\"last_deposit_{col}\")\n",
    "                                         )\n",
    "            feats=feats.join(feat,on='case_id',how='left')\n",
    "    del deposit\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"{mode} other file after break number 1\")\n",
    "    other=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_other_1.csv\").pipe(set_table_dtypes)\n",
    "    other_last=find_last_case_id(other)\n",
    "    \n",
    "    \n",
    "    last_features=[['amtdepositbalance_4809441A',0]\n",
    "                  ]\n",
    "    feats=last_features_merge(feats,other_last,last_features)\n",
    "\n",
    "    group_features=[['amtdebitincoming_4809443A',0],\n",
    "                     ['amtdebitoutgoing_4809440A',0],\n",
    "                     ['amtdepositincoming_4809444A',0], \n",
    "                     ['amtdepositoutgoing_4809442A',0]\n",
    "                   ]\n",
    "    feats=group_features_merge(feats,other,group_features,group_name='other')\n",
    "    \n",
    "    del other,other_last\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    print(\"person 1 num 1\")\n",
    "    person1=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_person_1.csv\").pipe(set_table_dtypes)\n",
    "    \n",
    "    person1=person1.drop(['birthdate_87D','childnum_185L','gender_992L','housingtype_772L','isreference_387L','maritalst_703L','role_993L'])                   \n",
    "    \n",
    "    person1=person1.select(['case_id','contaddr_matchlist_1032L','contaddr_smempladdr_334L','empl_employedtotal_800L','language1_981M',\n",
    "                           'persontype_1072L','persontype_792L','remitter_829L','role_1084L','safeguarantyflag_411L','sex_738L'])\n",
    "    person1_last=find_last_case_id(person1)\n",
    "    feats=feats.join(person1_last,on='case_id',how='left')\n",
    "    \n",
    "    del person1,person1_last\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    print(f\"{mode} person2 file after break number 1\")\n",
    "    \n",
    "    person2=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_person_2.csv\").pipe(set_table_dtypes)\n",
    "    \n",
    "    person2=person2.drop(['addres_role_871L','empls_employedfrom_796D','relatedpersons_role_762T'])\n",
    "    \n",
    "    person2=person2.drop(['addres_district_368M','addres_zip_823M','empls_employer_name_740M'])\n",
    "    \n",
    "    group_features=[['conts_role_79M','a55475b1',\n",
    "                     ['a55475b1', 'P38_92_157', 'P7_147_157', 'P177_137_98', 'P125_14_176', \n",
    "                      'P125_105_50', 'P115_147_77', 'P58_79_51','P124_137_181', 'P206_38_166', 'P42_134_91']\n",
    "                    ],\n",
    "                    ['empls_economicalst_849M','a55475b1',\n",
    "                    ['a55475b1', 'P164_110_33', 'P22_131_138', 'P28_32_178','P148_57_109', 'P7_47_145', 'P164_122_65', 'P112_86_147','P82_144_169', 'P191_80_124']\n",
    "                    ],\n",
    "                    ['num_group1',0],\n",
    "                   ['num_group2',0],\n",
    "                   ]\n",
    "    del person2\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"static_0 file num 2(3)\")\n",
    "    \n",
    "    static_0_0=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_static_0_0.csv\").pipe(set_table_dtypes)\n",
    "    static_0_1=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_static_0_1.csv\").pipe(set_table_dtypes)\n",
    "    \n",
    "    static=pl.concat([static_0_0,static_0_1],how=\"vertical_relaxed\")\n",
    "    if mode=='test':\n",
    "        static_0_2=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_static_0_2.csv\").pipe(set_table_dtypes)\n",
    "        static=pl.concat([static,static_0_2],how=\"vertical_relaxed\")\n",
    "    feats=feats.join(static,on='case_id',how='left')\n",
    "    del static,static_0_0,static_0_1\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"{mode} static_cb_file after break num 1\")\n",
    "    static_cb=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_static_cb_0.csv\").pipe(set_table_dtypes)\n",
    "    \n",
    "    static_cb=static_cb.drop(['assignmentdate_4955616D', 'dateofbirth_342D','for3years_128L',\n",
    "                            'for3years_504L','for3years_584L','formonth_118L','formonth_206L','formonth_535L',\n",
    "                           'forquarter_1017L', 'forquarter_462L','forquarter_634L','fortoday_1092L',\n",
    "                           'forweek_1077L','forweek_528L','forweek_601L','foryear_618L','foryear_818L','foryear_850L','pmtaverage_4955615A','pmtcount_4955617L','riskassesment_302T','riskassesment_940T'])\n",
    "    static_cb=static_cb.drop(['birthdate_574D','dateofbirth_337D',\n",
    "                             'assignmentdate_238D','assignmentdate_4527235D',\n",
    "                              'responsedate_1012D','responsedate_4527233D','responsedate_4917613D',\n",
    "                             ])\n",
    "    \n",
    "    \n",
    "    last_features=[ ['contractssum_5085716L',0],\n",
    "                    ['days120_123L',0],\n",
    "                    ['days180_256L',0],\n",
    "                    ['days30_165L',0],\n",
    "                    ['days360_512L',1],\n",
    "                    ['days90_310L',0],\n",
    "                    ['description_5085714M','a55475b1'],\n",
    "                    \n",
    "                    ['education_88M','a55475b1'],\n",
    "                    ['firstquarter_103L',0],\n",
    "                    ['secondquarter_766L',0],\n",
    "                    ['thirdquarter_1082L',0],\n",
    "                    ['fourthquarter_440L',0],\n",
    "                    ['maritalst_385M','a55475b1'],\n",
    "                    \n",
    "                    ['numberofqueries_373L',1],\n",
    "                    ['pmtaverage_3A',0],\n",
    "                    \n",
    "                    \n",
    "                    ['pmtcount_693L', 6],\n",
    "                    ['pmtscount_423L',6.0],\n",
    "                    ['pmtssum_45A',0],\n",
    "                    ['requesttype_4525192L','DEDUCTION_6'],\n",
    "                  ]\n",
    "    feats=last_features_merge(feats,static_cb,last_features)\n",
    "    \n",
    "    feats=feats.with_columns( (pl.col('days180_256L')-pl.col('days120_123L')).alias(\"daysgap60\"))\n",
    "    feats=feats.with_columns( (pl.col('days180_256L')-pl.col('days30_165L')).alias(\"daysgap150\"))\n",
    "    feats=feats.with_columns( (pl.col('days120_123L')-pl.col('days30_165L')).alias(\"daysgap90\"))\n",
    "    \n",
    "    feats=feats.with_columns( (pl.col('firstquarter_103L')+pl.col('secondquarter_766L')+pl.col('thirdquarter_1082L')+pl.col('fourthquarter_440L')).alias(\"totalyear_result\"))\n",
    "    \n",
    "    del static_cb\n",
    "    gc.collect()\n",
    "    print(\"-\"*30)\n",
    "    \n",
    "    print(f\"{mode} tax_a file after break num 1\")\n",
    "    tax_a=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_tax_registry_a_1.csv\").pipe(set_table_dtypes)\n",
    "    \n",
    "    group_features=[['amount_4527230A',850],\n",
    "                     ['num_group1',0]\n",
    "                   ]\n",
    "    feats=group_features_merge(feats,tax_a,group_features,group_name='tax_a')\n",
    "    del tax_a\n",
    "    gc.collect()\n",
    "    print(\"-\"*30)\n",
    "    \n",
    "    print(f\"{mode} tax_b file after break num 1\")\n",
    "    tax_b=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_tax_registry_b_1.csv\").pipe(set_table_dtypes)\n",
    "    \n",
    "    group_features=[['amount_4917619A',6885],\n",
    "                    ['num_group1',0]\n",
    "                  ]\n",
    "    feats=group_features_merge(feats,tax_b,group_features,group_name='tax_b')\n",
    "    del tax_b\n",
    "    gc.collect()\n",
    "    print(\"-\"*30)\n",
    "    \n",
    "    print(f\"{mode} tax_c file after break num 1\")\n",
    "    tax_c=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_tax_registry_c_1.csv\").pipe(set_table_dtypes)\n",
    "    if len(tax_c)==0:\n",
    "        tax_c=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/train/train_tax_registry_c_1.csv\").pipe(set_table_dtypes)\n",
    "        \n",
    "    \n",
    "    tax_c=tax_c.drop(['employername_160M','processingdate_168D'])\n",
    "    \n",
    "    group_features=[['pmtamount_36A',850],\n",
    "                    ['num_group1',0]\n",
    "                  ]\n",
    "    feats=group_features_merge(feats,tax_c,group_features,group_name='tax_c')\n",
    "    del tax_c\n",
    "    gc.collect()\n",
    "    print(\"-\"*30)\n",
    "    \n",
    "    return feats\n",
    "train_feats=preprocessor(mode='train')\n",
    "test_feats=preprocessor(mode='test')\n",
    "\n",
    "train_feats=train_feats.to_pandas()\n",
    "test_feats=test_feats.to_pandas()\n",
    "\n",
    "\n",
    "mode_values = train_feats.mode().iloc[0]\n",
    "\n",
    "train_feats = train_feats.fillna(mode_values)\n",
    "\n",
    "test_feats = test_feats.fillna(mode_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74427a9c",
   "metadata": {
    "_cell_guid": "af2b2e6c-a838-44a1-b682-846f2977ee42",
    "_uuid": "0f2f79d2-c484-4b7d-ae78-e0d5a9d59044",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-06T10:53:02.072218Z",
     "iopub.status.busy": "2024-06-06T10:53:02.071724Z",
     "iopub.status.idle": "2024-06-06T10:55:21.692784Z",
     "shell.execute_reply": "2024-06-06T10:55:21.691625Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 139.629987,
     "end_time": "2024-06-06T10:55:21.695210",
     "exception": false,
     "start_time": "2024-06-06T10:53:02.065223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------string one hot encoder ****\n",
      "one_hot_10:conts_type_509L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:periodicityofpmts_997L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:periodicityofpmts_997M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:pmtmethod_731M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:subjectrole_326M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:subjectrole_43M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:contaddr_matchlist_1032L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_2:contaddr_smempladdr_334L\n",
      "one_hot_10:empl_employedtotal_800L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:language1_981M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:remitter_829L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:role_1084L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_2:safeguarantyflag_411L\n",
      "one_hot_2:sex_738L\n",
      "one_hot_10:bankacctype_710L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_2:cardtype_51L\n",
      "one_hot_10:credtype_322L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:disbursementtype_67L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_2:equalitydataagreement_891L\n",
      "one_hot_2:equalityempfrom_62L\n",
      "one_hot_10:inittransactioncode_186L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_2:isbidproduct_1095L\n",
      "one_hot_10:isbidproductrequest_292L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:isdebitcard_729L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_2:opencred_647L\n",
      "one_hot_10:paytype1st_925L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:paytype_783L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_2:twobodfilling_608L\n",
      "one_hot_10:typesuite_864L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_2:description_5085714M\n",
      "one_hot_10:education_88M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:maritalst_385M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_10:requesttype_4525192L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
      "/tmp/ipykernel_18/2385975480.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------drop other string or unique value or full null value ****\n",
      "len(train_feats):1526659,total_features_counts:405\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>frozen_credit</th>\n",
       "      <th>mean_applprev2_cacccardblochreas_147M_P19_60_110</th>\n",
       "      <th>std_applprev2_cacccardblochreas_147M_P19_60_110</th>\n",
       "      <th>count_applprev2_cacccardblochreas_147M_P19_60_110</th>\n",
       "      <th>mean_applprev2_cacccardblochreas_147M_P17_56_144</th>\n",
       "      <th>std_applprev2_cacccardblochreas_147M_P17_56_144</th>\n",
       "      <th>count_applprev2_cacccardblochreas_147M_P17_56_144</th>\n",
       "      <th>mean_applprev2_cacccardblochreas_147M_a55475b1</th>\n",
       "      <th>std_applprev2_cacccardblochreas_147M_a55475b1</th>\n",
       "      <th>...</th>\n",
       "      <th>education_88M_4</th>\n",
       "      <th>maritalst_385M_0</th>\n",
       "      <th>maritalst_385M_1</th>\n",
       "      <th>maritalst_385M_2</th>\n",
       "      <th>maritalst_385M_3</th>\n",
       "      <th>maritalst_385M_4</th>\n",
       "      <th>maritalst_385M_5</th>\n",
       "      <th>requesttype_4525192L_0</th>\n",
       "      <th>requesttype_4525192L_1</th>\n",
       "      <th>requesttype_4525192L_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  406 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  frozen_credit  mean_applprev2_cacccardblochreas_147M_P19_60_110  \\\n",
       "0       0            1.0                                               0.0   \n",
       "1       0            1.0                                               0.0   \n",
       "2       0            0.0                                               0.0   \n",
       "3       0            0.0                                               0.0   \n",
       "4       1            0.0                                               0.0   \n",
       "\n",
       "   std_applprev2_cacccardblochreas_147M_P19_60_110  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   count_applprev2_cacccardblochreas_147M_P19_60_110  \\\n",
       "0                                                2.0   \n",
       "1                                                2.0   \n",
       "2                                                4.0   \n",
       "3                                                3.0   \n",
       "4                                                2.0   \n",
       "\n",
       "   mean_applprev2_cacccardblochreas_147M_P17_56_144  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   std_applprev2_cacccardblochreas_147M_P17_56_144  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   count_applprev2_cacccardblochreas_147M_P17_56_144  \\\n",
       "0                                                2.0   \n",
       "1                                                2.0   \n",
       "2                                                4.0   \n",
       "3                                                3.0   \n",
       "4                                                2.0   \n",
       "\n",
       "   mean_applprev2_cacccardblochreas_147M_a55475b1  \\\n",
       "0                                             1.0   \n",
       "1                                             1.0   \n",
       "2                                             1.0   \n",
       "3                                             1.0   \n",
       "4                                             1.0   \n",
       "\n",
       "   std_applprev2_cacccardblochreas_147M_a55475b1  ...  education_88M_4  \\\n",
       "0                                            0.0  ...                0   \n",
       "1                                            0.0  ...                0   \n",
       "2                                            0.0  ...                0   \n",
       "3                                            0.0  ...                0   \n",
       "4                                            0.0  ...                0   \n",
       "\n",
       "   maritalst_385M_0  maritalst_385M_1  maritalst_385M_2  maritalst_385M_3  \\\n",
       "0                 1                 0                 0                 0   \n",
       "1                 1                 0                 0                 0   \n",
       "2                 1                 0                 0                 0   \n",
       "3                 1                 0                 0                 0   \n",
       "4                 1                 0                 0                 0   \n",
       "\n",
       "   maritalst_385M_4  maritalst_385M_5  requesttype_4525192L_0  \\\n",
       "0                 0                 0                       1   \n",
       "1                 0                 0                       1   \n",
       "2                 0                 0                       1   \n",
       "3                 0                 0                       1   \n",
       "4                 0                 0                       1   \n",
       "\n",
       "   requesttype_4525192L_1  requesttype_4525192L_2  \n",
       "0                       0                       0  \n",
       "1                       0                       0  \n",
       "2                       0                       0  \n",
       "3                       0                       0  \n",
       "4                       0                       0  \n",
       "\n",
       "[5 rows x 406 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"----------string one hot encoder ****\")\n",
    "for col in test_feats.columns:\n",
    "    n_unique=train_feats[col].nunique()\n",
    "    \n",
    "    \n",
    "    if n_unique==2 and train_feats[col].dtype=='object':\n",
    "        print(f\"one_hot_2:{col}\")\n",
    "        unique=train_feats[col].unique()\n",
    "        \n",
    "        train_feats[col]=(train_feats[col]==unique[0]).astype(int)\n",
    "        test_feats[col]=(test_feats[col]==unique[0]).astype(int)\n",
    "    elif (n_unique<10) and train_feats[col].dtype=='object':\n",
    "        print(f\"one_hot_10:{col}\")\n",
    "        unique=train_feats[col].unique()\n",
    "        for idx in range(len(unique)):\n",
    "            if unique[idx]==unique[idx]:\n",
    "                train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
    "                test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
    "        train_feats.drop([col],axis=1,inplace=True)\n",
    "        test_feats.drop([col],axis=1,inplace=True)\n",
    "print(\"----------drop other string or unique value or full null value ****\")\n",
    "drop_cols=[]\n",
    "for col in test_feats.columns:\n",
    "    if (train_feats[col].dtype=='object') or (test_feats[col].dtype=='object') \\\n",
    "        or (train_feats[col].nunique()==1) or train_feats[col].isna().mean()>0.99:\n",
    "        drop_cols+=[col]\n",
    "\n",
    "drop_cols+=['case_id']\n",
    "train_feats.drop(drop_cols,axis=1,inplace=True)\n",
    "test_feats.drop(drop_cols,axis=1,inplace=True)\n",
    "print(f\"len(train_feats):{len(train_feats)},total_features_counts:{len(test_feats.columns)}\")\n",
    "train_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3af6af",
   "metadata": {
    "_cell_guid": "0a6ab88c-4858-4e32-96c0-8cb2654c3e32",
    "_uuid": "ef60310e-0a25-43d4-b2f9-11c88716e124",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-06T10:55:21.718151Z",
     "iopub.status.busy": "2024-06-06T10:55:21.717727Z",
     "iopub.status.idle": "2024-06-06T10:55:25.737226Z",
     "shell.execute_reply": "2024-06-06T10:55:25.735927Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.033677,
     "end_time": "2024-06-06T10:55:25.739405",
     "exception": false,
     "start_time": "2024-06-06T10:55:21.705728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 4728.88 MB\n",
      "Memory usage after optimization is: 1988.81 MB\n",
      "Decreased by 57.9%\n",
      "Memory usage of dataframe is 0.03 MB\n",
      "Memory usage after optimization is: 0.01 MB\n",
      "Decreased by 57.6%\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df, float16_as32=True):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min,c_max = df[col].min(),df[col].max() \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                \n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                \n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    if float16_as32:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float16)  \n",
    "                \n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                \n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    \n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "train_feats = reduce_mem_usage(train_feats)\n",
    "test_feats = reduce_mem_usage(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ae16a2",
   "metadata": {
    "_cell_guid": "eb136074-b94a-48a7-abdc-0f11aca4675f",
    "_uuid": "a4b1e8d9-eb6a-4995-9277-199c521074f2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-06T10:55:25.764931Z",
     "iopub.status.busy": "2024-06-06T10:55:25.763987Z",
     "iopub.status.idle": "2024-06-06T10:55:32.578089Z",
     "shell.execute_reply": "2024-06-06T10:55:32.576974Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 6.830123,
     "end_time": "2024-06-06T10:55:32.580307",
     "exception": false,
     "start_time": "2024-06-06T10:55:25.750184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(choose_cols):304,choose_cols:['frozen_credit', 'count_applprev2_cacccardblochreas_147M_P19_60_110', 'count_applprev2_cacccardblochreas_147M_P17_56_144', 'mean_applprev2_cacccardblochreas_147M_a55475b1', 'std_applprev2_cacccardblochreas_147M_a55475b1', 'count_applprev2_cacccardblochreas_147M_a55475b1', 'mean_applprev2_cacccardblochreas_147M_P201_63_60', 'std_applprev2_cacccardblochreas_147M_P201_63_60', 'count_applprev2_cacccardblochreas_147M_P201_63_60', 'count_applprev2_cacccardblochreas_147M_P127_74_114', 'count_applprev2_cacccardblochreas_147M_P133_119_56', 'count_applprev2_cacccardblochreas_147M_P41_107_150', 'count_applprev2_cacccardblochreas_147M_P23_105_103P33_145_161', 'mean_applprev2_credacc_cards_status_52L_BLOCKED', 'std_applprev2_credacc_cards_status_52L_BLOCKED', 'count_applprev2_credacc_cards_status_52L_BLOCKED', 'mean_applprev2_credacc_cards_status_52L_UNCONFIRMED', 'std_applprev2_credacc_cards_status_52L_UNCONFIRMED', 'count_applprev2_credacc_cards_status_52L_UNCONFIRMED', 'mean_applprev2_credacc_cards_status_52L_RENEWED', 'count_applprev2_credacc_cards_status_52L_RENEWED', 'mean_applprev2_credacc_cards_status_52L_CANCELLED', 'std_applprev2_credacc_cards_status_52L_CANCELLED', 'count_applprev2_credacc_cards_status_52L_CANCELLED', 'mean_applprev2_credacc_cards_status_52L_INACTIVE', 'std_applprev2_credacc_cards_status_52L_INACTIVE', 'count_applprev2_credacc_cards_status_52L_INACTIVE', 'std_applprev2_credacc_cards_status_52L_ACTIVE', 'count_applprev2_credacc_cards_status_52L_ACTIVE', 'max_applprev2_num_group1', 'mean_applprev2_num_group1', 'median_applprev2_num_group1', 'std_applprev2_num_group1', 'count_applprev2_num_group1', 'sum_applprev2_num_group1', 'n_unique_applprev2_num_group1', 'last_applprev2_num_group1', 'max_applprev2_num_group2', 'mean_applprev2_num_group2', 'median_applprev2_num_group2', 'std_applprev2_num_group2', 'count_applprev2_num_group2', 'n_unique_applprev2_num_group2', 'last_applprev2_num_group2', 'credlmt_1052A', 'credlmt_228A', 'credquantity_1099L', 'credquantity_984L', 'debtpastduevalue_732A', 'dpd_550P', 'dpdmax_851P', 'dpdmaxdatemonth_804T', 'dpdmaxdateyear_742T', 'maxdebtpduevalodued_3940955A', 'num_group1', 'numberofinstls_810L', 'overdueamountmax_950A', 'overdueamountmaxdatemonth_494T', 'overdueamountmaxdateyear_432T', 'pmtdaysoverdue_1135P', 'pmtnumpending_403L', 'residualamount_127A', 'residualamount_3940956A', 'totalamount_881A', 'num_group1_right', 'num_group2', 'pmts_dpdvalue_108P', 'max_debitcard_num_group1', 'mean_debitcard_num_group1', 'median_debitcard_num_group1', 'std_debitcard_num_group1', 'count_debitcard_num_group1', 'n_unique_debitcard_num_group1', 'last_debitcard_num_group1', 'max_deposit_amount_416A', 'mean_deposit_amount_416A', 'median_deposit_amount_416A', 'std_deposit_amount_416A', 'min_deposit_amount_416A', 'count_deposit_amount_416A', 'sum_deposit_amount_416A', 'n_unique_deposit_amount_416A', 'first_deposit_amount_416A', 'last_deposit_amount_416A', 'max_deposit_num_group1', 'mean_deposit_num_group1', 'median_deposit_num_group1', 'std_deposit_num_group1', 'count_deposit_num_group1', 'n_unique_deposit_num_group1', 'first_deposit_num_group1', 'last_deposit_num_group1', 'amtdepositbalance_4809441A', 'persontype_1072L', 'persontype_792L', 'sex_738L', 'actualdpdtolerance_344P', 'annuity_780A', 'annuitynextmonth_57A', 'applications30d_658L', 'applicationscnt_464L', 'applicationscnt_629L', 'applicationscnt_867L', 'avgdbddpdlast24m_3658932P', 'avgdpdtolclosure24_3658938P', 'avginstallast24m_3658937A', 'avgmaxdpdlast9m_3716943P', 'clientscnt12m_3712952L', 'clientscnt3m_3712950L', 'clientscnt6m_3712949L', 'clientscnt_100L', 'clientscnt_1022L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_360L', 'clientscnt_533L', 'clientscnt_887L', 'cntincpaycont9m_3716944L', 'cntpmts24_3658933L', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'daysoverduetolerancedd_3976961L', 'disbursedcredamount_1113A', 'downpmt_116A', 'eir_270L', 'equalitydataagreement_891L', 'equalityempfrom_62L', 'homephncnt_628L', 'interestrate_311L', 'isbidproduct_1095L', 'lastrejectcredamount_222A', 'maininc_215A', 'maxannuity_159A', 'maxdbddpdlast1m_3658939P', 'maxdbddpdtollast12m_3658940P', 'maxdebt4_972A', 'maxdpdfrom6mto36m_3546853P', 'maxdpdinstlnum_3546846P', 'maxdpdlast12m_727P', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdlast6m_474P', 'maxdpdlast9m_1059P', 'maxdpdtolerance_374P', 'mindbddpdlast24m_3658935P', 'mobilephncnt_593L', 'monthsannuity_845L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numincomingpmts_3546848L', 'numinstlallpaidearly3d_817L', 'numinstls_657L', 'numinstlsallpaid_934L', 'numinstlswithdpd10_728L', 'numinstlswithoutdpd_562L', 'numinstpaidearly3d_3546850L', 'numinstpaidearly5d_1087L', 'numinstpaidearly_338L', 'numinstpaidlate1d_3546852L', 'numinstregularpaid_973L', 'numinsttopaygr_769L', 'numinstunpaidmax_3546851L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'opencred_647L', 'pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlat10d_839L', 'pctinstlsallpaidlate1d_3546856L', 'pctinstlsallpaidlate4d_3546849L', 'pctinstlsallpaidlate6d_3546844L', 'pmtnum_254L', 'posfpd10lastmonth_333P', 'posfpd30lastmonth_3976960P', 'posfstqpd30lastmonth_3976962P', 'price_1097A', 'sellerplacecnt_915L', 'sellerplacescnt_216L', 'sumoutstandtotal_3546847A', 'totaldebt_9A', 'totalsettled_863A', 'twobodfilling_608L', 'days120_123L', 'days180_256L', 'days30_165L', 'days360_512L', 'days90_310L', 'description_5085714M', 'firstquarter_103L', 'secondquarter_766L', 'thirdquarter_1082L', 'fourthquarter_440L', 'numberofqueries_373L', 'pmtaverage_3A', 'pmtcount_693L', 'pmtscount_423L', 'pmtssum_45A', 'daysgap60', 'daysgap150', 'daysgap90', 'totalyear_result', 'max_tax_a_amount_4527230A', 'mean_tax_a_amount_4527230A', 'median_tax_a_amount_4527230A', 'std_tax_a_amount_4527230A', 'min_tax_a_amount_4527230A', 'count_tax_a_amount_4527230A', 'sum_tax_a_amount_4527230A', 'n_unique_tax_a_amount_4527230A', 'first_tax_a_amount_4527230A', 'last_tax_a_amount_4527230A', 'max_tax_a_num_group1', 'mean_tax_a_num_group1', 'median_tax_a_num_group1', 'std_tax_a_num_group1', 'count_tax_a_num_group1', 'sum_tax_a_num_group1', 'n_unique_tax_a_num_group1', 'first_tax_a_num_group1', 'last_tax_a_num_group1', 'max_tax_b_amount_4917619A', 'mean_tax_b_amount_4917619A', 'median_tax_b_amount_4917619A', 'std_tax_b_amount_4917619A', 'min_tax_b_amount_4917619A', 'count_tax_b_amount_4917619A', 'sum_tax_b_amount_4917619A', 'n_unique_tax_b_amount_4917619A', 'first_tax_b_amount_4917619A', 'last_tax_b_amount_4917619A', 'max_tax_b_num_group1', 'mean_tax_b_num_group1', 'median_tax_b_num_group1', 'std_tax_b_num_group1', 'count_tax_b_num_group1', 'sum_tax_b_num_group1', 'n_unique_tax_b_num_group1', 'first_tax_b_num_group1', 'last_tax_b_num_group1', 'max_tax_c_pmtamount_36A', 'mean_tax_c_pmtamount_36A', 'median_tax_c_pmtamount_36A', 'std_tax_c_pmtamount_36A', 'min_tax_c_pmtamount_36A', 'count_tax_c_pmtamount_36A', 'sum_tax_c_pmtamount_36A', 'n_unique_tax_c_pmtamount_36A', 'first_tax_c_pmtamount_36A', 'last_tax_c_pmtamount_36A', 'max_tax_c_num_group1', 'mean_tax_c_num_group1', 'median_tax_c_num_group1', 'std_tax_c_num_group1', 'count_tax_c_num_group1', 'sum_tax_c_num_group1', 'n_unique_tax_c_num_group1', 'last_tax_c_num_group1', 'conts_type_509L_3', 'conts_type_509L_4', 'periodicityofpmts_997M_0', 'periodicityofpmts_997M_1', 'periodicityofpmts_997M_2', 'periodicityofpmts_997M_3', 'pmtmethod_731M_0', 'pmtmethod_731M_2', 'pmtmethod_731M_3', 'pmtmethod_731M_4', 'pmtmethod_731M_5', 'subjectrole_326M_0', 'subjectrole_326M_1', 'subjectrole_43M_0', 'subjectrole_43M_1', 'subjectrole_43M_2', 'language1_981M_0', 'language1_981M_1', 'language1_981M_2', 'role_1084L_0', 'role_1084L_1', 'credtype_322L_0', 'credtype_322L_1', 'credtype_322L_2', 'disbursementtype_67L_0', 'disbursementtype_67L_1', 'disbursementtype_67L_2', 'inittransactioncode_186L_0', 'inittransactioncode_186L_1', 'inittransactioncode_186L_2', 'education_88M_0', 'education_88M_1', 'education_88M_2', 'education_88M_3', 'maritalst_385M_0', 'maritalst_385M_1', 'maritalst_385M_2', 'maritalst_385M_3', 'maritalst_385M_5', 'requesttype_4525192L_0', 'requesttype_4525192L_1', 'requesttype_4525192L_2']\n"
     ]
    }
   ],
   "source": [
    "def pearson_corr(x1,x2):\n",
    "    \"\"\"\n",
    "    x1,x2:np.array\n",
    "    \"\"\"\n",
    "    mean_x1=np.mean(x1)\n",
    "    mean_x2=np.mean(x2)\n",
    "    std_x1=np.std(x1)\n",
    "    std_x2=np.std(x2)\n",
    "    pearson=np.mean((x1-mean_x1)*(x2-mean_x2))/(std_x1*std_x2)\n",
    "    return pearson\n",
    "\n",
    "choose_cols=[]\n",
    "for col in train_feats.columns:\n",
    "    if col!='target':\n",
    "        pearson=pearson_corr(train_feats[col].values,train_feats['target'].values) \n",
    "        if abs(pearson)>0.0025:\n",
    "            choose_cols.append(col)\n",
    "print(f\"len(choose_cols):{len(choose_cols)},choose_cols:{choose_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e7a626d",
   "metadata": {
    "_cell_guid": "42838091-24ea-42f7-a006-5d7906e2b8b1",
    "_uuid": "7d524123-ee49-4782-924e-a178ba32e369",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-06T10:55:32.604428Z",
     "iopub.status.busy": "2024-06-06T10:55:32.604006Z",
     "iopub.status.idle": "2024-06-06T10:55:32.609711Z",
     "shell.execute_reply": "2024-06-06T10:55:32.608386Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020711,
     "end_time": "2024-06-06T10:55:32.612213",
     "exception": false,
     "start_time": "2024-06-06T10:55:32.591502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pickle_dump(obj, path):\n",
    "    with open(path, mode=\"wb\") as f:\n",
    "        dill.dump(obj, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44e670e",
   "metadata": {
    "_cell_guid": "82b7aeec-ec72-4f7f-8c0a-237e667c914a",
    "_uuid": "6ce93277-b869-42e2-ab96-1c0534c7fc9a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-06T10:55:32.636337Z",
     "iopub.status.busy": "2024-06-06T10:55:32.635925Z",
     "iopub.status.idle": "2024-06-06T10:59:25.419637Z",
     "shell.execute_reply": "2024-06-06T10:59:25.418453Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 232.798933,
     "end_time": "2024-06-06T10:59:25.422304",
     "exception": false,
     "start_time": "2024-06-06T10:55:32.623371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:0\n",
      "fold:1\n",
      "fold:2\n",
      "fold:3\n",
      "fold:4\n",
      "fold:5\n",
      "fold:6\n",
      "fold:7\n",
      "fold:8\n",
      "fold:9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X=train_feats[choose_cols].copy()\n",
    "y=train_feats[Config.TARGET_NAME].copy()\n",
    "test_X=test_feats[choose_cols].copy()\n",
    "oof_pred_pro=np.zeros((len(X)))\n",
    "test_pred_pro=np.zeros((Config.num_folds,len(test_X)))\n",
    "del train_feats,test_feats\n",
    "gc.collect()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=Config.num_folds,random_state=Config.seed, shuffle=True)\n",
    "\n",
    "for fold, (train_index, valid_index) in (enumerate(skf.split(X, y.astype(str)))):\n",
    "    print(f\"fold:{fold}\")\n",
    "\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pickle_dump(model, f'/kaggle/working/linear_fold{fold}.model')\n",
    "    \n",
    "    del model,X_train, X_valid,y_train, y_valid\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    },
    {
     "sourceId": 166996856,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 527.126165,
   "end_time": "2024-06-06T10:59:26.558837",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-06T10:50:39.432672",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
